else if(x>1 && x<=1.25) c=4
else if(x>1.25 && x<=1.5) c=5
else if(x>1.5 && x<=1.75) c=6
else if (x<0) c=0
else c=7
y=(1/(1 + exp(-0.1*x ))*0.25)+c/4
return(y)
}
sigmoidd(data$throughput[1])
sigmoidd<-function(x){
if(x>0.25 && x<=0.5) c=1
else if(x>0.5 && x<=0.75) c=2
else if(x>0.75 && x<=1) c=3
else if(x>1 && x<=1.25) c=4
else if(x>1.25 && x<=1.5) c=5
else if(x>1.5 && x<=1.75) c=6
else if (x<0) c=0
else c=7
y=(1/(1 + exp(-0.1*x ))*0.25)+c/4
return(y)
}
sigmoidd(data$throughput[341])
y_new_th=NULL
for (i in 1:nrow(data)){
y_new_th[i]= sigmoidd(data$throughput[i])
}
data=cbind(data,y_new_th)
krr_ahmed <- function(x, y, lambda, degree =2) {
x <- as.matrix(x)
n <- nrow(x)
p <- ncol(x)
if (length(y) != n) stop("Error: x and y of different lengths!")
poly <- polydot(degree=degree)
k <- kernelMatrix(poly, x)
alpha_hat <- solve(K + lambda*n*diag(n)) %*% y
f_hat <- K %*% alpha_hat
residuals <- f_hat - y
MSE <- mean((f_hat - y)^2)
erreur <- (abs(f_hat - y)/y)*100
mean_error=mean(erreur)
out <- list("pred" = f_hat,
"alpha_hat" = alpha_hat,
"lambda" = lambda,
"ker" = rbf,
"x" = x,
"residuals" = residuals,
"MSE" = MSE,
"Erreur"=erreur,
"Mean_erreur"=mean_error)
class(out) <- "krr"
return(out)
}
cv_krr <- function(x,y,breaks,times,lambdas_to_try,sigmas_to_try) {
data_test=cbind(x,y)
data_test=as.data.frame(data_test)
data_test<-data_test[sample(nrow(data_test)),]
#Create 10 equally size folds
folds <- cut(seq(1,nrow(data_test)),breaks=breaks,labels=FALSE)
#Perform 10 fold cross validation
lambda_best_list=list()
sigma_best_list=list()
mean_erreur_list=list()
test_matrix=diag(0,length(lambdas_to_try),length(sigmas_to_try))
for(k in 1:times){
#Segement your data by fold using the which() function
testIndexes <- which(folds==k,arr.ind=TRUE)
x_testData <- data_test[testIndexes, ]
x_trainData <- data_test[-testIndexes, ]
y_traindata= x_trainData[,dim(data_test)[2]]
y_testdata=x_testData[,dim(data_test)[2]]
x_testData[,dim(data_test)[2]]=NULL
x_trainData[,dim(data_test)[2]]=NULL
test_MSE <- function(lambda,sigma,x_tr,x_ts,y_tr,y_ts) {
mod <- krr_ahmed(x_tr, y_tr,lambda,sigma)
Mean_error <- predict.krr(mod, x_ts, y_ts)$Mean_erreur
return(Mean_error)
}
matrix_Mean_error=diag(0,length(lambdas_to_try),length(sigmas_to_try))
for (i in 1:length(lambdas_to_try)) {
for (j in 1:length(sigmas_to_try)) {
matrix_Mean_error[i,j]=test_MSE(lambdas_to_try[i],sigmas_to_try[j],x_trainData,x_testData,y_traindata,y_testdata)
}
}
ind=which(matrix_Mean_error==min(matrix_Mean_error),arr.ind = T)
lambda_best_list[k] <- lambdas_to_try[ind[,1]]
sigma_best_list[k] <- sigmas_to_try[ind[,2]]
mean_erreur_list[k] = min(matrix_Mean_error)
test_matrix=test_matrix+matrix_Mean_error
}
test_matrix=test_matrix/times
ind=which(test_matrix==min(test_matrix),arr.ind = T)
lambda_best <- lambdas_to_try[ind[,1]]
sigma_best <- sigmas_to_try[ind[,2]]
model_best_final <- krr_ahmed(x,y,as.double(lambda_best),as.double(sigma_best))
return(list("lambda_best" = lambda_best,
"sigma_best" =sigma_best,
"lambda_best_list" =lambda_best_list,
"sigma_best_list" =sigma_best_list,
"mean_erreur_list" =mean_erreur_list,
"Mean_erreur"=test_matrix,
"model_best" = model_best_final))
}
calcul2=function(c){
if (c[3]!=c[7]){
alpha1= (c[3])/(c[7]);
P1_0= (1-alpha1)/(1-alpha1^(c[4]+1));
P1_N1= ((alpha1^c[4])*(1-alpha1))/(1-alpha1^(c[4]+1));
b1=(1-P1_N1);
b2=(1-P1_0);
psi1= c[3]* (c[2]*b1) /(c[1]*b1+ c[2]);
psi2=c[7]*(b2*c[6])/(c[5]*b2+ c[6]);
Throughput= min (psi1,psi2);
}
else {
P1_0= (1)/(c[4]+1);
P1_N1= (1)/(c[4]+1);
b1=(1-P1_N1);
b2=(1-P1_0);
psi1= c[3]* (c[2]*b1) /(c[1]*b1+ c[2]);
psi2=c[7]*(b2*c[6])/(c[5]*b2+ c[6]);
Throughput= min (psi1,psi2);
}
return(Throughput)
}
lambda1=sample(round(seq(0.01,0.1,length.out=40),3),size = 400,replace = T)
lambda2=sample(round(seq(0.01,0.1,length.out=40),3),size = 400,replace = T)
mu1=sample(round(seq(0.1,0.9,length.out=40),3),size = 400,replace = T)
mu2=sample(round(seq(0.1,0.9,length.out=40),3),size = 400,replace = T)
omega1=seq(0.5,2.75,by=0.25)
omega2=c(rep(0.5,10),rep(0.75,10),rep(1,10),rep(1.25,10),rep(1.5,10),rep(1.75,10),rep(2,10),rep(2.25,10),rep(2.5,10),rep(2.75,10))
n1=sample(seq(2,100,by=2))
data=cbind(lambda1,mu1,omega1,n1,lambda2,mu2,omega2)
throughput=NULL
for (i in 1:dim(data)[1]) {
c=data[i,]
throughput=rbind(throughput,round(calcul2(c),5))
}
data=cbind(data,throughput)
colnames(data)=c("lambda1","mu1","omega1" ,"n1","lambda2","mu2","omega2","throughput")
data=as.data.frame(data)
set.seed(101)
data=as.data.frame(data)
sample = sample.split(data$throughput,SplitRatio = 0.8)
x_train1 = subset(data,sample==TRUE)
x_test1 = subset(data,sample== FALSE)
y_train1 <- x_train1$throughput
y_test1 <- x_test1$throughput
x_train1$throughput <- NULL
x_test1$throughput <- NULL
predict.krr <- function(krr_mod, xnew, ynew = NULL) {
xnew <- as.matrix(xnew)
nnew <- nrow(xnew)
pnew <- ncol(xnew)
x <- krr_mod$x
n <- nrow(x)
as.matrix(x)
ker <- krr_mod$ker
K_tilde <- kernlab::kernelMatrix(ker, xnew, x)
f_tilde <- K_tilde %*% krr_mod$alpha_hat
if (!is.null(ynew)) {
MSE <- mean((f_tilde - ynew)^2)
erreur <- (abs(f_tilde - ynew)/ynew)*100
mean_error=mean(erreur)
return(list(
'pred' = f_tilde,
'MSE' = MSE,
"Erreur"=erreur,
"Mean_erreur"=mean_error
))
} else {
return(f_tilde)
}
}
calcul2=function(c){
if (c[3]!=c[7]){
alpha1= (c[3])/(c[7]);
P1_0= (1-alpha1)/(1-alpha1^(c[4]+1));
P1_N1= ((alpha1^c[4])*(1-alpha1))/(1-alpha1^(c[4]+1));
b1=(1-P1_N1);
b2=(1-P1_0);
psi1= c[3]* (c[2]*b1) /(c[1]*b1+ c[2]);
psi2=c[7]*(b2*c[6])/(c[5]*b2+ c[6]);
Throughput= min (psi1,psi2);
}
else {
P1_0= (1)/(c[4]+1);
P1_N1= (1)/(c[4]+1);
b1=(1-P1_N1);
b2=(1-P1_0);
psi1= c[3]* (c[2]*b1) /(c[1]*b1+ c[2]);
psi2=c[7]*(b2*c[6])/(c[5]*b2+ c[6]);
Throughput= min (psi1,psi2);
}
return(list("throughput"=Throughput,
"psi1"=psi1,
"psi2"=psi2
))
}
lambdas_to_try <-c(2^seq(-10,0,length.out = 21))
sigmas_to_try=c(1,2^seq(-3,3,length.out=20))
cv.model=cv_krr(x_train1,y_train1,10,10,lambdas_to_try,sigmas_to_try=sigmas_to_try)
y_predicted=predict.krr1(cv.model$model_best,x_test1,y_test1)
erreur1=y_predicted$Mean_erreur
tab_comp=cbind(y_predicted$pred,y_test1)
install.packages("kernlab")
library(kernlab)
poly <- polydot(degree=degree)
krr_ahmed <- function(x, y, lambda, degree =2) {
x <- as.matrix(x)
n <- nrow(x)
p <- ncol(x)
if (length(y) != n) stop("Error: x and y of different lengths!")
poly <- polydot(degree=degree)
k <- kernelMatrix(poly, x)
alpha_hat <- solve(K + lambda*n*diag(n)) %*% y
f_hat <- K %*% alpha_hat
residuals <- f_hat - y
MSE <- mean((f_hat - y)^2)
erreur <- (abs(f_hat - y)/y)*100
mean_error=mean(erreur)
out <- list("pred" = f_hat,
"alpha_hat" = alpha_hat,
"lambda" = lambda,
"ker" = rbf,
"x" = x,
"residuals" = residuals,
"MSE" = MSE,
"Erreur"=erreur,
"Mean_erreur"=mean_error)
class(out) <- "krr"
return(out)
}
lambdas_to_try <-c(2^seq(-10,0,length.out = 21))
sigmas_to_try=c(1,2^seq(-3,3,length.out=20))
cv.model=cv_krr(x_train1,y_train1,10,10,lambdas_to_try,sigmas_to_try=sigmas_to_try)
y_predicted=predict.krr1(cv.model$model_best,x_test1,y_test1)
erreur1=y_predicted$Mean_erreur
tab_comp=cbind(y_predicted$pred,y_test1)
poly <- polydot(degree=2)
k <- kernelMatrix(poly, x)
krr_ahmed <- function(x, y, lambda, degree =2) {
x <- as.matrix(x)
n <- nrow(x)
p <- ncol(x)
if (length(y) != n) stop("Error: x and y of different lengths!")
poly <- polydot(degree=degree)
k <- kernelMatrix(poly, x)
alpha_hat <- solve(K + lambda*n*diag(n)) %*% y
f_hat <- K %*% alpha_hat
residuals <- f_hat - y
MSE <- mean((f_hat - y)^2)
erreur <- (abs(f_hat - y)/y)*100
mean_error=mean(erreur)
out <- list("pred" = f_hat,
"alpha_hat" = alpha_hat,
"lambda" = lambda,
"ker" = rbf,
"x" = x,
"residuals" = residuals,
"MSE" = MSE,
"Erreur"=erreur,
"Mean_erreur"=mean_error)
class(out) <- "krr"
return(out)
}
lambdas_to_try <-c(2^seq(-10,0,length.out = 21))
sigmas_to_try=c(1,2^seq(-3,3,length.out=20))
cv.model=cv_krr(x_train1,y_train1,10,10,lambdas_to_try,sigmas_to_try=sigmas_to_try)
y_predicted=predict.krr1(cv.model$model_best,x_test1,y_test1)
erreur1=y_predicted$Mean_erreur
tab_comp=cbind(y_predicted$pred,y_test1)
krr_ahmed <- function(x, y, lambda, degree =2) {
x <- as.matrix(x)
n <- nrow(x)
p <- ncol(x)
if (length(y) != n) stop("Error: x and y of different lengths!")
poly <- polydot(degree=degree)
k <- kernelMatrix(poly, x)
alpha_hat <- solve(kernelMatrix(poly, x)  + lambda*n*diag(n)) %*% y
f_hat <- K %*% alpha_hat
residuals <- f_hat - y
MSE <- mean((f_hat - y)^2)
erreur <- (abs(f_hat - y)/y)*100
mean_error=mean(erreur)
out <- list("pred" = f_hat,
"alpha_hat" = alpha_hat,
"lambda" = lambda,
"ker" = rbf,
"x" = x,
"residuals" = residuals,
"MSE" = MSE,
"Erreur"=erreur,
"Mean_erreur"=mean_error)
class(out) <- "krr"
return(out)
}
lambdas_to_try <-c(2^seq(-10,0,length.out = 21))
sigmas_to_try=c(1,2^seq(-3,3,length.out=20))
cv.model=cv_krr(x_train1,y_train1,10,10,lambdas_to_try,sigmas_to_try=sigmas_to_try)
y_predicted=predict.krr1(cv.model$model_best,x_test1,y_test1)
erreur1=y_predicted$Mean_erreur
tab_comp=cbind(y_predicted$pred,y_test1)
krr_ahmed <- function(x, y, lambda, degree =2) {
x <- as.matrix(x)
n <- nrow(x)
p <- ncol(x)
if (length(y) != n) stop("Error: x and y of different lengths!")
poly <- polydot(degree=degree)
k <- kernelMatrix(poly, x)
alpha_hat <- solve(kernelMatrix(poly, x)  + lambda*n*diag(n)) %*% y
f_hat <- kernelMatrix(poly, x)  %*% alpha_hat
residuals <- f_hat - y
MSE <- mean((f_hat - y)^2)
erreur <- (abs(f_hat - y)/y)*100
mean_error=mean(erreur)
out <- list("pred" = f_hat,
"alpha_hat" = alpha_hat,
"lambda" = lambda,
"ker" = rbf,
"x" = x,
"residuals" = residuals,
"MSE" = MSE,
"Erreur"=erreur,
"Mean_erreur"=mean_error)
class(out) <- "krr"
return(out)
}
lambdas_to_try <-c(2^seq(-10,0,length.out = 21))
sigmas_to_try=c(1,2^seq(-3,3,length.out=20))
cv.model=cv_krr(x_train1,y_train1,10,10,lambdas_to_try,sigmas_to_try=sigmas_to_try)
y_predicted=predict.krr1(cv.model$model_best,x_test1,y_test1)
erreur1=y_predicted$Mean_erreur
tab_comp=cbind(y_predicted$pred,y_test1)
krr_ahmed <- function(x, y, lambda, degree =2) {
x <- as.matrix(x)
n <- nrow(x)
p <- ncol(x)
if (length(y) != n) stop("Error: x and y of different lengths!")
poly <- polydot(degree=degree)
k <- kernelMatrix(poly, x)
alpha_hat <- solve(kernelMatrix(poly, x)  + lambda*n*diag(n)) %*% y
f_hat <- kernelMatrix(poly, x)  %*% alpha_hat
residuals <- f_hat - y
MSE <- mean((f_hat - y)^2)
erreur <- (abs(f_hat - y)/y)*100
mean_error=mean(erreur)
out <- list("pred" = f_hat,
"alpha_hat" = alpha_hat,
"lambda" = lambda,
"ker" = poly,
"x" = x,
"residuals" = residuals,
"MSE" = MSE,
"Erreur"=erreur,
"Mean_erreur"=mean_error)
class(out) <- "krr"
return(out)
}
lambdas_to_try <-c(2^seq(-10,0,length.out = 21))
sigmas_to_try=c(1,2^seq(-3,3,length.out=20))
cv.model=cv_krr(x_train1,y_train1,10,10,lambdas_to_try,sigmas_to_try=sigmas_to_try)
y_predicted=predict.krr1(cv.model$model_best,x_test1,y_test1)
erreur1=y_predicted$Mean_erreur
tab_comp=cbind(y_predicted$pred,y_test1)
krr_ahmed <- function(x, y, lambda, degree =1) {
x <- as.matrix(x)
n <- nrow(x)
p <- ncol(x)
if (length(y) != n) stop("Error: x and y of different lengths!")
poly <- laplacedot(sigma=degree)
k <- kernelMatrix(poly, x)
alpha_hat <- solve(kernelMatrix(poly, x)  + lambda*n*diag(n)) %*% y
f_hat <- kernelMatrix(poly, x)  %*% alpha_hat
residuals <- f_hat - y
MSE <- mean((f_hat - y)^2)
erreur <- (abs(f_hat - y)/y)*100
mean_error=mean(erreur)
out <- list("pred" = f_hat,
"alpha_hat" = alpha_hat,
"lambda" = lambda,
"ker" = poly,
"x" = x,
"residuals" = residuals,
"MSE" = MSE,
"Erreur"=erreur,
"Mean_erreur"=mean_error)
class(out) <- "krr"
return(out)
}
lambdas_to_try <-c(2^seq(-10,0,length.out = 21))
sigmas_to_try=c(1,2^seq(-3,3,length.out=20))
cv.model=cv_krr(x_train1,y_train1,10,10,lambdas_to_try,sigmas_to_try=sigmas_to_try)
y_predicted=predict.krr1(cv.model$model_best,x_test1,y_test1)
erreur1=y_predicted$Mean_erreur
tab_comp=cbind(y_predicted$pred,y_test1)
predict.krr1 <- function(krr_mod, xnew, ynew = NULL) {
xnew <- as.matrix(xnew)
nnew <- nrow(xnew)
pnew <- ncol(xnew)
x <- krr_mod$x
n <- nrow(x)
as.matrix(x)
ker <- krr_mod$ker
K_tilde <- kernlab::kernelMatrix(ker, xnew, x)
f_tilde <- K_tilde %*% krr_mod$alpha_hat
if (!is.null(ynew)) {
MSE <- mean((f_tilde - ynew)^2)
erreur <- (abs(f_tilde - ynew)/ynew)*100
mean_error=mean(erreur)
return(list(
'pred' = f_tilde,
'MSE' = MSE,
"Erreur"=erreur,
"Mean_erreur"=mean_error
))
} else {
return(f_tilde)
}
}
y_predicted=predict.krr1(cv.model$model_best,x_test1,y_test1)
erreur1=y_predicted$Mean_erreur
erreur1
krr_ahmed <- function(x, y, lambda, degree =0.5) {
x <- as.matrix(x)
n <- nrow(x)
p <- ncol(x)
if (length(y) != n) stop("Error: x and y of different lengths!")
poly <- laplacedot(sigma=degree)
k <- kernelMatrix(poly, x)
alpha_hat <- solve(kernelMatrix(poly, x)  + lambda*n*diag(n)) %*% y
f_hat <- kernelMatrix(poly, x)  %*% alpha_hat
residuals <- f_hat - y
MSE <- mean((f_hat - y)^2)
erreur <- (abs(f_hat - y)/y)*100
mean_error=mean(erreur)
out <- list("pred" = f_hat,
"alpha_hat" = alpha_hat,
"lambda" = lambda,
"ker" = poly,
"x" = x,
"residuals" = residuals,
"MSE" = MSE,
"Erreur"=erreur,
"Mean_erreur"=mean_error)
class(out) <- "krr"
return(out)
}
cv.model=cv_krr(x_train1,y_train1,10,10,lambdas_to_try,sigmas_to_try=sigmas_to_try)
y_predicted=predict.krr1(cv.model$model_best,x_test1,y_test1)
erreur1=y_predicted$Mean_erreur
erreur1
krr_ahmed <- function(x, y, lambda, degree =0.5) {
x <- as.matrix(x)
n <- nrow(x)
p <- ncol(x)
if (length(y) != n) stop("Error: x and y of different lengths!")
poly <- besseldot(sigma=degree)
k <- kernelMatrix(poly, x)
alpha_hat <- solve(kernelMatrix(poly, x)  + lambda*n*diag(n)) %*% y
f_hat <- kernelMatrix(poly, x)  %*% alpha_hat
residuals <- f_hat - y
MSE <- mean((f_hat - y)^2)
erreur <- (abs(f_hat - y)/y)*100
mean_error=mean(erreur)
out <- list("pred" = f_hat,
"alpha_hat" = alpha_hat,
"lambda" = lambda,
"ker" = poly,
"x" = x,
"residuals" = residuals,
"MSE" = MSE,
"Erreur"=erreur,
"Mean_erreur"=mean_error)
class(out) <- "krr"
return(out)
}
lambdas_to_try <-c(2^seq(-10,0,length.out = 21))
sigmas_to_try=c(1,2^seq(-3,3,length.out=20))
cv.model=cv_krr(x_train1,y_train1,10,10,lambdas_to_try,sigmas_to_try=sigmas_to_try)
y_predicted=predict.krr1(cv.model$model_best,x_test1,y_test1)
erreur1=y_predicted$Mean_erreur
erreur1
krr_ahmed <- function(x, y, lambda, degree =1) {
x <- as.matrix(x)
n <- nrow(x)
p <- ncol(x)
if (length(y) != n) stop("Error: x and y of different lengths!")
poly <- laplacedot(sigma=degree)
k <- kernelMatrix(poly, x)
alpha_hat <- solve(kernelMatrix(poly, x)  + lambda*n*diag(n)) %*% y
f_hat <- kernelMatrix(poly, x)  %*% alpha_hat
residuals <- f_hat - y
MSE <- mean((f_hat - y)^2)
erreur <- (abs(f_hat - y)/y)*100
mean_error=mean(erreur)
out <- list("pred" = f_hat,
"alpha_hat" = alpha_hat,
"lambda" = lambda,
"ker" = poly,
"x" = x,
"residuals" = residuals,
"MSE" = MSE,
"Erreur"=erreur,
"Mean_erreur"=mean_error)
class(out) <- "krr"
return(out)
}
x_train_norm=scale(x_train1,center = colMeans(x_train1),scale=apply(x_train1,2,sd))
x_test_norm=scale(x_test1,center = colMeans(x_train1),scale=apply(x_train1,2,sd))
cv.model4=cv_krr(x_train_norm,y_train1,8,8,lambdas_to_try,sigmas_to_try=sigmas_to_try)
shiny::runApp()
runApp()
